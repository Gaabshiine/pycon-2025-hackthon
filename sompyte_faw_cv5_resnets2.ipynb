{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84de42d",
   "metadata": {},
   "source": [
    "\n",
    "# SomPyte — FAW CV5 (ResNet18/34) — **Auto‑Path**\n",
    "This version **auto‑detects** `Train.csv`, `Test.csv` and the `Images/` folder anywhere inside your cloned repo.\n",
    "It then trains 5‑fold CV for **ResNet18** and **ResNet34** and saves:\n",
    "- `submission_cv5_resnet18.csv`\n",
    "- `submission_cv5_resnet34.csv`\n",
    "- `submission_blend_r18_r34.csv`\n",
    "\n",
    "> Works with: `https://github.com/Gaabshiine/pycon-2025-hackthon.git`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [setup] (install minimal deps if missing)\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg.split('==')[0].split('[')[0])\n",
    "    except Exception:\n",
    "        print(f\"Installing: {pkg}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "for p in [\"tqdm\", \"scikit-learn\", \"torchvision\", \"pandas\", \"numpy\", \"Pillow\"]:\n",
    "    pip_install(p)\n",
    "print(\"✅ deps ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [imports]\n",
    "import os, math, random, time, gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ed50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [paths] Auto-detect Train.csv/Test.csv/Images anywhere in repo\n",
    "def find_data_root(start: Path):\n",
    "    # search for Train.csv and Test.csv (case-insensitive) and an Images folder\n",
    "    lower_ok = False\n",
    "    for p in [start, *start.rglob(\"*\")]:\n",
    "        train_u = p / \"Train.csv\"\n",
    "        test_u  = p / \"Test.csv\"\n",
    "        images_u = p / \"Images\"\n",
    "        train_l = p / \"train.csv\"\n",
    "        test_l  = p / \"test.csv\"\n",
    "        images_l = p / \"images\"\n",
    "        if train_u.exists() and test_u.exists() and (images_u.exists() or images_l.exists()):\n",
    "            return p, train_u, test_u, images_u if images_u.exists() else images_l\n",
    "        if train_l.exists() and test_l.exists() and (images_u.exists() or images_l.exists()):\n",
    "            lower_ok = True\n",
    "            return p, train_l, test_l, images_u if images_u.exists() else images_l\n",
    "    raise FileNotFoundError(\"Could not find Train.csv/Test.csv/Images folder. Please verify repo structure.\")\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "DATA_DIR, TRAIN_CSV, TEST_CSV, IMAGES_DIR = find_data_root(REPO_ROOT)\n",
    "print(\"DATA_DIR =\", DATA_DIR)\n",
    "print(\"TRAIN   =\", TRAIN_CSV)\n",
    "print(\"TEST    =\", TEST_CSV)\n",
    "print(\"IMAGES  =\", IMAGES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [config]\n",
    "SEED = 42\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 48\n",
    "EPOCHS = 12\n",
    "N_FOLDS = 5\n",
    "TTA = True  # horizontal flip only\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    import random, numpy as np, torch\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [load dfs]\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff72c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [dataset]\n",
    "class FAWDataset(Dataset):\n",
    "    def __init__(self, df, root, train=True, transforms=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = Path(root)\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.root / row[\"Image_id\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        if self.train:\n",
    "            y = torch.tensor(row[\"Label\"], dtype=torch.float32)\n",
    "            return img, y\n",
    "        else:\n",
    "            return img, row[\"Image_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [transforms]\n",
    "train_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(12),\n",
    "    T.RandomPerspective(distortion_scale=0.15, p=0.25),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "valid_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [model + ema]\n",
    "def build_model(backbone=\"resnet18\"):\n",
    "    if backbone == \"resnet18\":\n",
    "        m = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    elif backbone == \"resnet34\":\n",
    "        m = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        raise ValueError(\"backbone must be resnet18 or resnet34\")\n",
    "    in_feats = m.fc.in_features\n",
    "    m.fc = nn.Linear(in_feats, 1)\n",
    "    return m\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {n: p.data.clone() for n,p in model.named_parameters() if p.requires_grad}\n",
    "    def update(self, model):\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.shadow[n] = (1-self.decay)*p.data + self.decay*self.shadow[n]\n",
    "    def apply_shadow(self, model):\n",
    "        self.bak = {}\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.bak[n] = p.data.clone()\n",
    "                p.data = self.shadow[n].clone()\n",
    "    def restore(self, model):\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.requires_grad and n in self.bak:\n",
    "                p.data = self.bak[n]\n",
    "        self.bak = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [train/valid]\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for imgs, y in loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        y = y.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        losses.append(loss.detach().item())\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    probs, targs = [], []\n",
    "    for imgs, y in loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        p = torch.sigmoid(model(imgs)).squeeze(1).detach().cpu().numpy()\n",
    "        probs.append(p); targs.append(y.numpy())\n",
    "    probs = np.concatenate(probs); targs = np.concatenate(targs)\n",
    "    auc = roc_auc_score(targs, probs)\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [cv5]\n",
    "def run_fold(df, fold, backbone=\"resnet18\"):\n",
    "    train_idx = df.index[df.kfold != fold]\n",
    "    valid_idx = df.index[df.kfold == fold]\n",
    "    dtr = df.loc[train_idx].reset_index(drop=True)\n",
    "    dvl = df.loc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    tr_ds = FAWDataset(dtr, IMAGES_DIR, True, train_tfms)\n",
    "    vl_ds = FAWDataset(dvl, IMAGES_DIR, True, valid_tfms)\n",
    "    te_ds = FAWDataset(df_test, IMAGES_DIR, False, valid_tfms)\n",
    "\n",
    "    tr = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    vl = DataLoader(vl_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    te = DataLoader(te_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    model = build_model(backbone).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "    scaler = torch.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "    ema = EMA(model, decay=0.999)\n",
    "\n",
    "    best_auc, best_path, patience = -1.0, f\"best_{backbone}_fold{fold}.pt\", 0\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        tr_loss = train_one_epoch(model, tr, opt, scaler)\n",
    "        ema.update(model)\n",
    "        ema.apply_shadow(model); val_auc = valid_one_epoch(model, vl); ema.restore(model)\n",
    "        sch.step()\n",
    "        print(f\"[{backbone}][fold {fold}][ep {ep}] loss={tr_loss:.4f} AUC={val_auc:.6f}\")\n",
    "        if val_auc > best_auc:\n",
    "            best_auc, patience = val_auc, 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 3: \n",
    "                print(\"Early stop.\"); break\n",
    "\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE)); model.eval()\n",
    "    # OOF\n",
    "    ema.apply_shadow(model)\n",
    "    v_probs = []\n",
    "    for imgs, y in vl:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        v_probs.append(torch.sigmoid(model(imgs)).squeeze(1).cpu().numpy())\n",
    "    ema.restore(model)\n",
    "    v_probs = np.concatenate(v_probs)\n",
    "    oof = pd.DataFrame({\"idx\": valid_idx, \"oof\": v_probs}).set_index(\"idx\")\n",
    "\n",
    "    # TEST (+flip TTA)\n",
    "    te_probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, ids in te:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            p = torch.sigmoid(model(imgs)).squeeze(1)\n",
    "            if True:\n",
    "                p = 0.5*(p + torch.sigmoid(model(torch.flip(imgs, dims=[3]))).squeeze(1))\n",
    "            te_probs.append(p.cpu().numpy())\n",
    "    te_probs = np.concatenate(te_probs)\n",
    "    return best_auc, oof, te_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [split]\n",
    "df = df_train.copy()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "df[\"kfold\"] = -1\n",
    "for f, (_, v) in enumerate(skf.split(df, df[\"Label\"])):\n",
    "    df.loc[v, \"kfold\"] = f\n",
    "df[\"kfold\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [run resnet18]\n",
    "bk = \"resnet18\"\n",
    "all_oof = np.zeros(len(df)); test_pred = np.zeros(len(df_test))\n",
    "fold_aucs = []\n",
    "for f in range(5):\n",
    "    auc, oof, te = run_fold(df, f, backbone=bk)\n",
    "    fold_aucs.append(auc); all_oof[oof.index.values] = oof[\"oof\"].values; test_pred += te/5\n",
    "print(f\"{bk} fold AUCs:\", fold_aucs, \"mean:\", np.mean(fold_aucs))\n",
    "print(\"OOF AUC:\", roc_auc_score(df[\"Label\"].values, all_oof))\n",
    "pd.DataFrame({\"Image_id\": df_test[\"Image_id\"], \"Label\": test_pred}).to_csv(\"submission_cv5_resnet18.csv\", index=False)\n",
    "print(\"Saved submission_cv5_resnet18.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [run resnet34]\n",
    "bk = \"resnet34\"\n",
    "all_oof = np.zeros(len(df)); test_pred = np.zeros(len(df_test))\n",
    "fold_aucs = []\n",
    "for f in range(5):\n",
    "    auc, oof, te = run_fold(df, f, backbone=bk)\n",
    "    fold_aucs.append(auc); all_oof[oof.index.values] = oof[\"oof\"].values; test_pred += te/5\n",
    "print(f\"{bk} fold AUCs:\", fold_aucs, \"mean:\", np.mean(fold_aucs))\n",
    "print(\"OOF AUC:\", roc_auc_score(df[\"Label\"].values, all_oof))\n",
    "pd.DataFrame({\"Image_id\": df_test[\"Image_id\"], \"Label\": test_pred}).to_csv(\"submission_cv5_resnet34.csv\", index=False)\n",
    "print(\"Saved submission_cv5_resnet34.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802585eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [blend]\n",
    "import pandas as pd\n",
    "a = pd.read_csv(\"submission_cv5_resnet18.csv\")\n",
    "b = pd.read_csv(\"submission_cv5_resnet34.csv\")\n",
    "m = a.merge(b, on=\"Image_id\", suffixes=(\"_r18\",\"_r34\"))\n",
    "m[\"Label\"] = 0.5*m[\"Label_r18\"] + 0.5*m[\"Label_r34\"]\n",
    "m[[\"Image_id\",\"Label\"]].to_csv(\"submission_blend_r18_r34.csv\", index=False)\n",
    "print(\"Saved submission_blend_r18_r34.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}