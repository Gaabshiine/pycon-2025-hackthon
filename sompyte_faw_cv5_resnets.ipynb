{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97afb301",
   "metadata": {},
   "source": [
    "# SomPyte — FAW CV5 (ResNet18/34)\n",
    "Binary image classification for fall armyworm (AUC metric). This notebook is **self-contained** and produces three files:\n",
    "\n",
    "- `submission_cv5_resnet18.csv`\n",
    "- `submission_cv5_resnet34.csv`\n",
    "- `submission_blend_r18_r34.csv`\n",
    "\n",
    "**Time-safe:** early stopping on AUC, AMP, simple TTA (flip). **Rules-safe:** probabilities only, no external data, ImageNet weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ddf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [setup] Install minimal packages (Colab-safe; local may already have them)\n",
    "# If running locally and you already have these, you can skip this cell.\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg.split('==')[0].split('[')[0])\n",
    "    except Exception:\n",
    "        print(f\"Installing: {pkg}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "for p in [\"tqdm\", \"scikit-learn\", \"torchvision\", \"pandas\", \"numpy\", \"Pillow\"]:\n",
    "    pip_install(p)\n",
    "print(\"✅ deps ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a955ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [imports]\n",
    "import os, math, random, time, gc, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [config]\n",
    "SEED = 42\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 48\n",
    "EPOCHS = 12\n",
    "N_FOLDS = 5\n",
    "TTA = True  # horizontal flip only\n",
    "\n",
    "# paths\n",
    "DATA_DIR = Path(\"./\")  # adjust if needed\n",
    "TRAIN_CSV = DATA_DIR / \"Train.csv\"\n",
    "TEST_CSV  = DATA_DIR / \"Test.csv\"\n",
    "IMAGES_DIR = DATA_DIR / \"Images\"  # expect images in ./Images/<image_id>\n",
    "\n",
    "assert TRAIN_CSV.exists(), \"Train.csv not found\"\n",
    "assert TEST_CSV.exists(), \"Test.csv not found\"\n",
    "assert IMAGES_DIR.exists(), \"Images folder not found (unzip Images.zip -> Images/)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2070ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [seed]\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726772e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [dataframe]\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [dataset]\n",
    "class FAWDataset(Dataset):\n",
    "    def __init__(self, df, root, train=True, transforms=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = Path(root)\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.root / row[\"Image_id\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        if self.train:\n",
    "            y = torch.tensor(row[\"Label\"], dtype=torch.float32)\n",
    "            return img, y\n",
    "        else:\n",
    "            return img, row[\"Image_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faba0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [transforms]\n",
    "train_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(12),\n",
    "    T.RandomPerspective(distortion_scale=0.15, p=0.25),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "valid_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [model]\n",
    "def build_model(backbone=\"resnet18\"):\n",
    "    if backbone == \"resnet18\":\n",
    "        m = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    elif backbone == \"resnet34\":\n",
    "        m = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        raise ValueError(\"backbone must be resnet18 or resnet34\")\n",
    "    in_feats = m.fc.in_features\n",
    "    m.fc = nn.Linear(in_feats, 1)\n",
    "    return m\n",
    "\n",
    "class EMA:\n",
    "    # simple EMA for model parameters\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self, model):\n",
    "        self.backup = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654568e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [train utils]\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for imgs, y in loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        y = y.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        losses.append(loss.detach().item())\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    probs, targs = [], []\n",
    "    for imgs, y in loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        logits = model(imgs)\n",
    "        p = torch.sigmoid(logits).squeeze(1).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "        targs.append(y.numpy())\n",
    "    probs = np.concatenate(probs)\n",
    "    targs = np.concatenate(targs)\n",
    "    auc = roc_auc_score(targs, probs)\n",
    "    return auc, float(np.mean(probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [cv fit/predict]\n",
    "def run_fold(df, fold, backbone=\"resnet18\"):\n",
    "    train_idx = df.index[df[\"kfold\"] != fold]\n",
    "    valid_idx = df.index[df[\"kfold\"] == fold]\n",
    "    dtr = df.loc[train_idx].reset_index(drop=True)\n",
    "    dvl = df.loc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    tr_ds = FAWDataset(dtr, IMAGES_DIR, train=True, transforms=train_tfms)\n",
    "    vl_ds = FAWDataset(dvl, IMAGES_DIR, train=True, transforms=valid_tfms)\n",
    "    te_ds = FAWDataset(df_test, IMAGES_DIR, train=False, transforms=valid_tfms)\n",
    "\n",
    "    tr_ld = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    vl_ld = DataLoader(vl_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    te_ld = DataLoader(te_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    model = build_model(backbone).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    scaler = torch.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "    ema = EMA(model, decay=0.999)\n",
    "\n",
    "    best_auc, best_path = -1.0, f\"best_{backbone}_fold{fold}.pt\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        tr_loss = train_one_epoch(model, tr_ld, optimizer, scaler)\n",
    "        ema.update(model)\n",
    "        # validate on EMA weights\n",
    "        ema.apply_shadow(model)\n",
    "        val_auc, _ = valid_one_epoch(model, vl_ld)\n",
    "        ema.restore(model)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"[{backbone}][fold {fold}][ep {epoch}] loss={tr_loss:.4f} AUC={val_auc:.6f}\")\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 3:\n",
    "                print(\"Early stop.\")\n",
    "                break\n",
    "\n",
    "    # load best\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    # valid oof probs (EMA for final scoring)\n",
    "    ema.apply_shadow(model)\n",
    "    v_probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y in vl_ld:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            p = torch.sigmoid(model(imgs)).squeeze(1).detach().cpu().numpy()\n",
    "            v_probs.append(p)\n",
    "    ema.restore(model)\n",
    "    v_probs = np.concatenate(v_probs)\n",
    "    oof = pd.DataFrame({\"idx\": valid_idx, \"oof\": v_probs}).set_index(\"idx\")\n",
    "\n",
    "    # test predictions (+ optional TTA flip)\n",
    "    te_probs = []\n",
    "    with torch.no_grad():\n",
    "        for (imgs, ids) in te_ld:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            p = torch.sigmoid(model(imgs)).squeeze(1)\n",
    "            if TTA:\n",
    "                p_flip = torch.sigmoid(model(torch.flip(imgs, dims=[3]))).squeeze(1)\n",
    "                p = 0.5*(p + p_flip)\n",
    "            te_probs.append(p.detach().cpu().numpy())\n",
    "    te_probs = np.concatenate(te_probs)\n",
    "\n",
    "    # cleanup\n",
    "    del model, tr_ld, vl_ld, te_ld; gc.collect(); torch.cuda.empty_cache()\n",
    "    return best_auc, oof, te_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [kfold split]\n",
    "df = df_train.copy()\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "df[\"kfold\"] = -1\n",
    "for f, (_, val_idx) in enumerate(skf.split(df, df[\"Label\"])):\n",
    "    df.loc[val_idx, \"kfold\"] = f\n",
    "df[\"kfold\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6767e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [CV5 ResNet18]\n",
    "backbone = \"resnet18\"\n",
    "all_oof = np.zeros(len(df))\n",
    "test_pred = np.zeros(len(df_test))\n",
    "\n",
    "fold_aucs = []\n",
    "for f in range(N_FOLDS):\n",
    "    auc, oof, te = run_fold(df, f, backbone=backbone)\n",
    "    fold_aucs.append(auc)\n",
    "    all_oof[oof.index.values] = oof[\"oof\"].values\n",
    "    test_pred += te / N_FOLDS\n",
    "\n",
    "print(f\"{backbone} fold AUCs:\", fold_aucs, \"mean:\", np.mean(fold_aucs))\n",
    "oof_auc = roc_auc_score(df[\"Label\"].values, all_oof)\n",
    "print(\"OOF AUC:\", oof_auc)\n",
    "\n",
    "sub18 = pd.DataFrame({\"Image_id\": df_test[\"Image_id\"], \"Label\": test_pred})\n",
    "sub18.to_csv(\"submission_cv5_resnet18.csv\", index=False)\n",
    "print(\"Saved submission_cv5_resnet18.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [CV5 ResNet34]\n",
    "backbone = \"resnet34\"\n",
    "all_oof = np.zeros(len(df))\n",
    "test_pred = np.zeros(len(df_test))\n",
    "\n",
    "fold_aucs = []\n",
    "for f in range(N_FOLDS):\n",
    "    auc, oof, te = run_fold(df, f, backbone=backbone)\n",
    "    fold_aucs.append(auc)\n",
    "    all_oof[oof.index.values] = oof[\"oof\"].values\n",
    "    test_pred += te / N_FOLDS\n",
    "\n",
    "print(f\"{backbone} fold AUCs:\", fold_aucs, \"mean:\", np.mean(fold_aucs))\n",
    "oof_auc = roc_auc_score(df[\"Label\"].values, all_oof)\n",
    "print(\"OOF AUC:\", oof_auc)\n",
    "\n",
    "sub34 = pd.DataFrame({\"Image_id\": df_test[\"Image_id\"], \"Label\": test_pred})\n",
    "sub34.to_csv(\"submission_cv5_resnet34.csv\", index=False)\n",
    "print(\"Saved submission_cv5_resnet34.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [blend]\n",
    "import pandas as pd\n",
    "a = pd.read_csv(\"submission_cv5_resnet18.csv\")\n",
    "b = pd.read_csv(\"submission_cv5_resnet34.csv\")\n",
    "m = a.merge(b, on=\"Image_id\", suffixes=(\"_r18\",\"_r34\"))\n",
    "m[\"Label\"] = 0.5*m[\"Label_r18\"] + 0.5*m[\"Label_r34\"]\n",
    "m[[\"Image_id\",\"Label\"]].to_csv(\"submission_blend_r18_r34.csv\", index=False)\n",
    "print(\"Saved submission_blend_r18_r34.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
