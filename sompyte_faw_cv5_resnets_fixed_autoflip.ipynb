{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05bf3fb",
   "metadata": {},
   "source": [
    "\n",
    "# SomPyte — FAW CV5 (ResNet18/34) — **AutoPath + AutoFlip (AUC)**\n",
    "Binary classification of fall armyworm on maize leaves.  \n",
    "This notebook **auto-detects** `Train.csv`, `Test.csv`, and `Images/` anywhere in your cloned repo, trains **5-fold CV** with **ResNet18** and **ResNet34**, and writes three submissions:\n",
    "\n",
    "- `submission_cv5_resnet18.csv`\n",
    "- `submission_cv5_resnet34.csv`\n",
    "- `submission_blend_r18_r34.csv`\n",
    "\n",
    "Safety features:\n",
    "- Early stopping on **AUC**\n",
    "- **EMA** weights for smoother validation\n",
    "- **AMP** for speed\n",
    "- Light **flip-TTA**\n",
    "- **AutoFlip**: if validation AUC < 0.5, invert probabilities for that fold (and test) to fix label inversion\n",
    "\n",
    "> Works with repo like: `https://github.com/Gaabshiine/pycon-2025-hackthon.git`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [setup] Install minimal deps if missing\n",
    "import sys, subprocess\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg.split('==')[0].split('[')[0])\n",
    "    except Exception:\n",
    "        print(f\"Installing: {pkg}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "for p in [\"tqdm\", \"scikit-learn\", \"torchvision\", \"pandas\", \"numpy\", \"Pillow\"]:\n",
    "    pip_install(p)\n",
    "print(\"✅ deps ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [imports]\n",
    "import os, random, gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [paths] Auto-detect Train.csv/Test.csv/Images anywhere in repo\n",
    "def find_data_root(start: Path):\n",
    "    for p in [start, *start.rglob(\"*\")]:\n",
    "        train_u = p / \"Train.csv\"\n",
    "        test_u  = p / \"Test.csv\"\n",
    "        images_u = p / \"Images\"\n",
    "        train_l = p / \"train.csv\"\n",
    "        test_l  = p / \"test.csv\"\n",
    "        images_l = p / \"images\"\n",
    "        if train_u.exists() and test_u.exists() and (images_u.exists() or images_l.exists()):\n",
    "            return p, train_u, test_u, images_u if images_u.exists() else images_l\n",
    "        if train_l.exists() and test_l.exists() and (images_u.exists() or images_l.exists()):\n",
    "            return p, train_l, test_l, images_u if images_u.exists() else images_l\n",
    "    raise FileNotFoundError(\"Could not find Train.csv/Test.csv/Images folder. Please verify repo structure.\")\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "DATA_DIR, TRAIN_CSV, TEST_CSV, IMAGES_DIR = find_data_root(REPO_ROOT)\n",
    "print(\"DATA_DIR =\", DATA_DIR)\n",
    "print(\"TRAIN    =\", TRAIN_CSV)\n",
    "print(\"TEST     =\", TEST_CSV)\n",
    "print(\"IMAGES   =\", IMAGES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [config]\n",
    "SEED = 42\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 48\n",
    "EPOCHS = 12\n",
    "N_FOLDS = 5\n",
    "TTA = True  # horizontal flip only\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    import numpy as np, torch, random\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede33783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [dataset]\n",
    "class FAWDataset(Dataset):\n",
    "    def __init__(self, df, root, train=True, transforms=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = Path(root)\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.root / row[\"Image_id\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transforms: img = self.transforms(img)\n",
    "        if self.train:\n",
    "            y = torch.tensor(row[\"Label\"], dtype=torch.float32)\n",
    "            return img, y\n",
    "        else:\n",
    "            return img, row[\"Image_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [transforms] (gentle to stabilize AUC)\n",
    "train_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "valid_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [model + ema]\n",
    "def build_model(backbone=\"resnet18\"):\n",
    "    if backbone == \"resnet18\":\n",
    "        m = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    elif backbone == \"resnet34\":\n",
    "        m = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        raise ValueError(\"backbone must be resnet18 or resnet34\")\n",
    "    in_feats = m.fc.in_features\n",
    "    m.fc = nn.Linear(in_feats, 1)\n",
    "    return m\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {n: p.data.clone() for n,p in model.named_parameters() if p.requires_grad}\n",
    "        self.bak = {}\n",
    "    def update(self, model):\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.shadow[n] = (1-self.decay)*p.data + self.decay*self.shadow[n]\n",
    "    def apply_shadow(self, model):\n",
    "        self.bak = {}\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.bak[n] = p.data.clone()\n",
    "                p.data = self.shadow[n].clone()\n",
    "    def restore(self, model):\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.requires_grad and n in self.bak:\n",
    "                p.data = self.bak[n]\n",
    "        self.bak = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [train/valid]\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for imgs, y in loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        y = y.to(DEVICE, non_blocking=True).unsqueeze(1)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        losses.append(loss.detach().item())\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    probs, targs = [], []\n",
    "    for imgs, y in loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        p = torch.sigmoid(model(imgs)).squeeze(1).detach().cpu().numpy()\n",
    "        probs.append(p); targs.append(y.numpy())\n",
    "    probs = np.concatenate(probs); targs = np.concatenate(targs)\n",
    "    auc = roc_auc_score(targs, probs)\n",
    "    auc_flip = roc_auc_score(targs, 1.0 - probs)\n",
    "    return auc, auc_flip, probs, targs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [cv5 run]\n",
    "def run_fold(df, fold, backbone=\"resnet18\"):\n",
    "    train_idx = df.index[df.kfold != fold]\n",
    "    valid_idx = df.index[df.kfold == fold]\n",
    "    dtr = df.loc[train_idx].reset_index(drop=True)\n",
    "    dvl = df.loc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    tr_ds = FAWDataset(dtr, IMAGES_DIR, True, train_tfms)\n",
    "    vl_ds = FAWDataset(dvl, IMAGES_DIR, True, valid_tfms)\n",
    "    te_ds = FAWDataset(df_test, IMAGES_DIR, False, valid_tfms)\n",
    "\n",
    "    tr = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    vl = DataLoader(vl_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    te = DataLoader(te_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    model = build_model(backbone).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "    scaler = torch.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "    ema = EMA(model, decay=0.999)\n",
    "\n",
    "    best_auc, best_path, patience = -1.0, f\"best_{backbone}_fold{fold}.pt\", 0\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        tr_loss = train_one_epoch(model, tr, opt, scaler)\n",
    "        ema.update(model)\n",
    "        ema.apply_shadow(model); val_auc, val_auc_flip, _, _ = valid_one_epoch(model, vl); ema.restore(model)\n",
    "        sch.step()\n",
    "        print(f\"[{backbone}][fold {fold}][ep {ep}] loss={tr_loss:.4f} AUC={val_auc:.6f} (flip {val_auc_flip:.6f})\")\n",
    "        score_for_earlystop = max(val_auc, val_auc_flip)  # be robust to inversion\n",
    "        if score_for_earlystop > best_auc:\n",
    "            best_auc, patience = score_for_earlystop, 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 3:\n",
    "                print(\"Early stop.\"); break\n",
    "\n",
    "    # load best\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE)); model.eval()\n",
    "\n",
    "    # ----- OOF (decide flip on full validation) -----\n",
    "    ema.apply_shadow(model)\n",
    "    v_probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y in vl:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            p = torch.sigmoid(model(imgs)).squeeze(1).detach().cpu().numpy()\n",
    "            v_probs.append(p)\n",
    "    ema.restore(model)\n",
    "    v_probs = np.concatenate(v_probs)\n",
    "\n",
    "    oof_auc = roc_auc_score(dvl[\"Label\"].values, v_probs)\n",
    "    oof_auc_flip = roc_auc_score(dvl[\"Label\"].values, 1.0 - v_probs)\n",
    "    flip_this_fold = oof_auc_flip > oof_auc\n",
    "    if flip_this_fold:\n",
    "        print(f\"[{backbone}][fold {fold}] ⚠️ Inversion detected — using flipped probs (AUC {oof_auc_flip:.6f} > {oof_auc:.6f})\")\n",
    "        v_probs = 1.0 - v_probs\n",
    "    oof = pd.DataFrame({\"idx\": valid_idx, \"oof\": v_probs}).set_index(\"idx\")\n",
    "\n",
    "    # ----- TEST (+flip TTA) -----\n",
    "    te_probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, ids in te:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            p = torch.sigmoid(model(imgs)).squeeze(1)\n",
    "            if TTA:\n",
    "                p = 0.5*(p + torch.sigmoid(model(torch.flip(imgs, dims=[3]))).squeeze(1))\n",
    "            p = p.detach().cpu().numpy()\n",
    "            if flip_this_fold:\n",
    "                p = 1.0 - p\n",
    "            te_probs.append(p)\n",
    "    te_probs = np.concatenate(te_probs)\n",
    "\n",
    "    return best_auc, oof, te_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [split + sanity fold labels]\n",
    "df = df_train.copy()\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "df[\"kfold\"] = -1\n",
    "for f, (_, v) in enumerate(skf.split(df, df[\"Label\"])):\n",
    "    df.loc[v, \"kfold\"] = f\n",
    "print(\"Fold label counts:\")\n",
    "for f in range(N_FOLDS):\n",
    "    print(f\"  Fold {f}:\", df.loc[df.kfold==f, \"Label\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [run resnet18]\n",
    "bk = \"resnet18\"\n",
    "all_oof = np.zeros(len(df)); test_pred = np.zeros(len(df_test))\n",
    "fold_aucs = []\n",
    "for f in range(N_FOLDS):\n",
    "    auc, oof, te = run_fold(df, f, backbone=bk)\n",
    "    fold_aucs.append(auc)\n",
    "    all_oof[oof.index.values] = oof[\"oof\"].values\n",
    "    test_pred += te / N_FOLDS\n",
    "print(f\"{bk} fold AUCs:\", fold_aucs, \"mean:\", np.mean(fold_aucs))\n",
    "print(\"OOF AUC (post flip if any):\", roc_auc_score(df['Label'].values, all_oof))\n",
    "pd.DataFrame({\"Image_id\": df_test[\"Image_id\"], \"Label\": test_pred}).to_csv(\"submission_cv5_resnet18.csv\", index=False)\n",
    "print(\"Saved submission_cv5_resnet18.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c430cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [run resnet34]\n",
    "bk = \"resnet34\"\n",
    "all_oof = np.zeros(len(df)); test_pred = np.zeros(len(df_test))\n",
    "fold_aucs = []\n",
    "for f in range(N_FOLDS):\n",
    "    auc, oof, te = run_fold(df, f, backbone=bk)\n",
    "    fold_aucs.append(auc)\n",
    "    all_oof[oof.index.values] = oof[\"oof\"].values\n",
    "    test_pred += te / N_FOLDS\n",
    "print(f\"{bk} fold AUCs:\", fold_aucs, \"mean:\", np.mean(fold_aucs))\n",
    "print(\"OOF AUC (post flip if any):\", roc_auc_score(df['Label'].values, all_oof))\n",
    "pd.DataFrame({\"Image_id\": df_test[\"Image_id\"], \"Label\": test_pred}).to_csv(\"submission_cv5_resnet34.csv\", index=False)\n",
    "print(\"Saved submission_cv5_resnet34.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [blend]\n",
    "import pandas as pd\n",
    "a = pd.read_csv(\"submission_cv5_resnet18.csv\")\n",
    "b = pd.read_csv(\"submission_cv5_resnet34.csv\")\n",
    "m = a.merge(b, on=\"Image_id\", suffixes=(\"_r18\",\"_r34\"))\n",
    "m[\"Label\"] = 0.5*m[\"Label_r18\"] + 0.5*m[\"Label_r34\"]\n",
    "m[[\"Image_id\",\"Label\"]].to_csv(\"submission_blend_r18_r34.csv\", index=False)\n",
    "print(\"Saved submission_blend_r18_r34.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
