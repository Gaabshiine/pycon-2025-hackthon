{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Install (safe)\n",
    "!pip -q install -U tqdm pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & config\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------- Repro & device ----------\n",
    "SEED = 1337\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------- Paths (your repo already cloned) ----------\n",
    "# If you haven't cloned in this runtime yet, uncomment:\n",
    "# !git clone https://github.com/Gaabshiine/pycon-2025-hackthon.git\n",
    "BASE_DIR   = Path('/content/pycon-2025-hackthon')\n",
    "IMAGES_DIR = BASE_DIR / 'Images'\n",
    "TRAIN_CSV  = BASE_DIR / 'Train.csv'\n",
    "TEST_CSV   = BASE_DIR / 'Test.csv'\n",
    "SAMPLE_SUB = BASE_DIR / 'SampleSubmission.csv'\n",
    "assert TRAIN_CSV.exists() and TEST_CSV.exists() and IMAGES_DIR.exists()\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "print(train_df.head())\n",
    "\n",
    "# ---------- T4-friendly hparams ----------\n",
    "IMG_SIZE    = 256          # try 320 if VRAM allows\n",
    "BATCH_SIZE  = 64           # 48/32 if OOM\n",
    "NUM_WORKERS = 0            # avoids Colab multiprocessing assertion\n",
    "PIN_MEMORY  = True\n",
    "\n",
    "EPOCHS          = 15\n",
    "LR              = 3e-4\n",
    "WARMUP_EPOCHS   = 1\n",
    "WEIGHT_DECAY    = 1e-4\n",
    "SMOOTH_EPS      = 0.05     # label smoothing\n",
    "\n",
    "BACKBONE = \"resnet18\"      # \"resnet18\" or \"resnet34\"\n",
    "FOLDS    = 3               # 3-fold CV ensemble\n",
    "\n",
    "# ---------- AMP (new API) ----------\n",
    "from contextlib import nullcontext\n",
    "autocast_ctx = torch.amp.autocast if torch.cuda.is_available() else nullcontext\n",
    "scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Quick EDA (optional)\n",
    "train_df['Label'].value_counts().sort_index().plot(kind=\"bar\", title=\"Class balance (0=healthy, 1=fall armyworm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44024282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Dataset & transforms\n",
    "class MaizeDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, mode='train', transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.images_dir / row['Image_id']  # CSV already has .jpg\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        if self.mode == 'test':\n",
    "            return img, row['Image_id']\n",
    "        else:\n",
    "            label = torch.tensor(float(row['Label']), dtype=torch.float32)\n",
    "            return img, label\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "valid_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41766ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Model, loss, scheduler\n",
    "def build_model():\n",
    "    if BACKBONE == \"resnet34\":\n",
    "        m = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    in_feats = m.fc.in_features\n",
    "    m.fc = nn.Linear(in_feats, 1)\n",
    "    return m\n",
    "\n",
    "def bce_with_logits_smooth(logits, labels, eps=SMOOTH_EPS):\n",
    "    # Smooth labels toward 0.5 to regularize\n",
    "    labels_s = labels * (1 - eps) + 0.5 * eps\n",
    "    return F.binary_cross_entropy_with_logits(logits, labels_s)\n",
    "\n",
    "def make_scheduler(optimizer):\n",
    "    def lr_lambda(e):\n",
    "        if e < WARMUP_EPOCHS:      # linear warmup\n",
    "            return (e + 1) / max(1, WARMUP_EPOCHS)\n",
    "        t = (e - WARMUP_EPOCHS) / max(1, (EPOCHS - WARMUP_EPOCHS))\n",
    "        return 0.5 * (1 + np.cos(np.pi * t))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3): \n",
    "        self.best = -np.inf; self.wait = 0; self.patience = patience\n",
    "    def step(self, val):\n",
    "        if val > self.best + 1e-4: self.best = val; self.wait = 0; return True\n",
    "        self.wait += 1; return False\n",
    "    def should_stop(self): return self.wait >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Train / Eval loops\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for imgs, labels in tqdm(loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast_ctx('cuda'):\n",
    "            logits = model(imgs)\n",
    "            loss = bce_with_logits_smooth(logits, labels)\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total += loss.item() * imgs.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_probs, all_targets = [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
    "        with autocast_ctx('cuda'):\n",
    "            probs = torch.sigmoid(model(imgs))\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_targets.append(labels.cpu().numpy())\n",
    "    probs = np.concatenate(all_probs).ravel()\n",
    "    targs = np.concatenate(all_targets).ravel()\n",
    "    return roc_auc_score(targs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00434fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) TTA inference helper\n",
    "@torch.no_grad()\n",
    "def predict_tta(model, imgs):\n",
    "    # orig + hflip + vflip (×3)\n",
    "    with autocast_ctx('cuda'):\n",
    "        logits  = model(imgs)\n",
    "        logits += model(torch.flip(imgs, [3]))\n",
    "        logits += model(torch.flip(imgs, [2]))\n",
    "    return torch.sigmoid(logits / 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 3-fold CV training + ensemble submission\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "test_ds = MaizeDataset(test_df, IMAGES_DIR, 'test', valid_tfms)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "test_preds = np.zeros(len(test_df), dtype=np.float32)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(train_df['Image_id'], train_df['Label']), 1):\n",
    "    print(f\"\\n========== Fold {fold}/{FOLDS} ==========\")\n",
    "    tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
    "    va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
    "\n",
    "    tr_ds = MaizeDataset(tr_df, IMAGES_DIR, 'train', train_tfms)\n",
    "    va_ds = MaizeDataset(va_df, IMAGES_DIR, 'train', valid_tfms)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    va_loader = DataLoader(va_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    model = build_model().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = make_scheduler(optimizer)\n",
    "    early = EarlyStopper(patience=3)\n",
    "\n",
    "    best_path = BASE_DIR / f'best_{BACKBONE}_fold{fold}.pt'\n",
    "    best_auc = -1\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        loss = train_one_epoch(model, tr_loader, optimizer, scaler)\n",
    "        val_auc = evaluate(model, va_loader)\n",
    "        print(f\"Fold {fold} | Epoch {epoch:02d} | loss {loss:.4f} | val_auc {val_auc:.6f}\")\n",
    "        if early.step(val_auc):\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            best_auc = val_auc\n",
    "            print(\"  ✓ Saved best\")\n",
    "        scheduler.step()\n",
    "        if early.should_stop():\n",
    "            print(\"  Early stopping.\")\n",
    "            break\n",
    "\n",
    "    # Load best & predict test\n",
    "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    model.eval()\n",
    "    fold_probs = []\n",
    "    for imgs, _ids in tqdm(test_loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        p = predict_tta(model, imgs).cpu().numpy().ravel()\n",
    "        fold_probs.append(p)\n",
    "    fold_probs = np.concatenate(fold_probs)\n",
    "    test_preds += fold_probs / FOLDS\n",
    "    print(f\"Fold {fold} best AUC: {best_auc:.6f}\")\n",
    "\n",
    "# Save ensemble submission\n",
    "sub = pd.DataFrame({'Image_id': test_df['Image_id'], 'Label': test_preds})\n",
    "sub_path = BASE_DIR / f'submission_cv{FOLDS}_{BACKBONE}_img{IMG_SIZE}.csv'\n",
    "sub.to_csv(sub_path, index=False)\n",
    "print(sub.head(), \"\\nSaved:\", sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(str(sub_path))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
