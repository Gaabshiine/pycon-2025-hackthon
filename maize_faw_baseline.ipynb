{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c42b0f80",
   "metadata": {},
   "source": [
    "\n",
    "# Maize Fall Armyworm — Baseline (PyTorch, ResNet18, AUC)\n",
    "\n",
    "Binary image classification to detect Fall Armyworm on maize leaves.  \n",
    "This notebook is **Colab-ready** (works on Tesla K80) and conforms to the hackathon rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 0. Install dependencies\n",
    "# =======================\n",
    "!pip -q install -U tqdm pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2da4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========\n",
    "# 1. Imports\n",
    "# ===========\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd14c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# 2. Settings\n",
    "# ============\n",
    "SEED = 1337\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Gaabshiine/pycon-2025-hackthon.git\n",
    "\n",
    "BASE_DIR   = Path('/content/pycon-2025-hackthon')\n",
    "IMAGES_DIR = BASE_DIR / 'Images'\n",
    "TRAIN_CSV  = BASE_DIR / 'Train.csv'\n",
    "TEST_CSV   = BASE_DIR / 'Test.csv'\n",
    "SAMPLE_SUB = BASE_DIR / 'SampleSubmission.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# 3. Quick EDA\n",
    "# ================\n",
    "counts = train_df['Label'].value_counts()\n",
    "counts.plot(kind=\"bar\", title=\"Class balance (0=Healthy, 1=Fall armyworm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae299c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# 4. Dataset class\n",
    "# ==================\n",
    "class MaizeDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, mode='train', transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['Image_id']  # full filename e.g. id_xxx.jpg\n",
    "        img_path = self.images_dir / img_id\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return img, img_id\n",
    "        else:\n",
    "            label = torch.tensor(float(row['Label']), dtype=torch.float32)\n",
    "            return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 5. Data transforms & split\n",
    "# ===========================\n",
    "IMG_SIZE   = 256     # T4-friendly\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "valid_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "train_split, valid_split = train_test_split(\n",
    "    train_df, test_size=0.2, stratify=train_df['Label'], random_state=SEED\n",
    ")\n",
    "\n",
    "train_ds = MaizeDataset(train_split, IMAGES_DIR, 'train', train_tfms)\n",
    "valid_ds = MaizeDataset(valid_split, IMAGES_DIR, 'train', valid_tfms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_loader = DataLoader(valid_ds, BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f89c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# 6. Model\n",
    "# ================\n",
    "def build_model():\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feats, 1)\n",
    "    return model\n",
    "\n",
    "model = build_model().to(device)\n",
    "print(\"Model params (M):\", sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7. Training utilities\n",
    "# ========================\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3):\n",
    "        self.best = -np.inf\n",
    "        self.wait = 0\n",
    "        self.patience = patience\n",
    "    def step(self, val):\n",
    "        if val > self.best + 1e-4:\n",
    "            self.best = val\n",
    "            self.wait = 0\n",
    "            return True\n",
    "        self.wait += 1\n",
    "        return False\n",
    "    def should_stop(self): return self.wait >= self.patience\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, labels in tqdm(loader, leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(imgs)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_probs, all_targets = [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)\n",
    "        probs = torch.sigmoid(model(imgs))\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_targets.append(labels.cpu().numpy())\n",
    "    all_probs = np.concatenate(all_probs).ravel()\n",
    "    all_targets = np.concatenate(all_targets).ravel()\n",
    "    return roc_auc_score(all_targets, all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# 8. Train loop\n",
    "# ==================\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "early = EarlyStopper(patience=3)\n",
    "\n",
    "best_path = BASE_DIR/'best_resnet18.pt'\n",
    "for epoch in range(1, 16):\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    val_auc = evaluate(model, valid_loader)\n",
    "    print(f\"Epoch {epoch}: loss={loss:.4f}, val_auc={val_auc:.4f}\")\n",
    "    if early.step(val_auc):\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(\"  ✓ Saved best model\")\n",
    "    if early.should_stop(): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeaf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# 9. Inference\n",
    "# ==================\n",
    "model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_ds = MaizeDataset(test_df, IMAGES_DIR, 'test', valid_tfms)\n",
    "test_loader = DataLoader(test_ds, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "probs, ids = [], []\n",
    "@torch.no_grad()\n",
    "def predict_tta(imgs):\n",
    "    return torch.sigmoid((model(imgs) + model(torch.flip(imgs,[3])))/2)\n",
    "\n",
    "for imgs, img_ids in tqdm(test_loader):\n",
    "    imgs = imgs.to(device)\n",
    "    p = predict_tta(imgs).cpu().numpy().ravel()\n",
    "    probs.extend(p); ids.extend(img_ids)\n",
    "\n",
    "sub = pd.DataFrame({'Image_id': ids, 'Label': probs})\n",
    "sub.to_csv(BASE_DIR/'submission.csv', index=False)\n",
    "print(sub.head())\n",
    "print(\"Saved submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# 10. Download file\n",
    "# ==================\n",
    "from google.colab import files\n",
    "files.download(str(BASE_DIR/'submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
