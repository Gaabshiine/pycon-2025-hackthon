{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c42b0f80",
   "metadata": {},
   "source": [
    "\n",
    "# Maize Fall Armyworm — Baseline (PyTorch, ResNet18, AUC)\n",
    "\n",
    "Binary image classification to detect Fall Armyworm on maize leaves.  \n",
    "This notebook is **Colab-ready** (works on Tesla K80) and conforms to the hackathon rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running on Colab, uncomment the next line to ensure sklearn is present (usually already installed).\n",
    "# !pip -q install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047946d6",
   "metadata": {},
   "source": [
    "## Quick EDA: Class balance & Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2da4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = train_df['Label'].value_counts().sort_index()\n",
    "print(counts)\n",
    "plt.figure()\n",
    "counts.plot(kind='bar')\n",
    "plt.title('Class counts (0=Healthy, 1=Fall Armyworm)')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd14c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show a few random training images with labels\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_df = train_df.sample(9, random_state=SEED).reset_index(drop=True)\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "for i, row in sample_df.iterrows():\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    img_path = resolve_image_path(row['Image_id'], IMAGES_DIR)\n",
    "    im = Image.open(img_path).convert('RGB')\n",
    "    plt.imshow(im)\n",
    "    ax.set_title(f\"{row['Label']} - {Path(img_path).name}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, time, random, shutil, glob, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED = 1337\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()\n",
    "print('PyTorch', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bd8f9",
   "metadata": {},
   "source": [
    "\n",
    "## Paths\n",
    "\n",
    "Set the paths below. If you're in Colab:\n",
    "- Upload/Unzip `Images.zip` into the working directory so that images live under `Images/`\n",
    "- Upload the three CSVs (`Train.csv`, `Test.csv`, `SampleSubmission.csv`) to the working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== CONFIG ====\n",
    "IMAGES_DIR = Path('Images')   # folder containing all images\n",
    "TRAIN_CSV = Path('Train.csv')\n",
    "TEST_CSV  = Path('Test.csv')\n",
    "SAMPLE_SUB = Path('SampleSubmission.csv')\n",
    "\n",
    "IMG_EXTS = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n",
    "\n",
    "assert TRAIN_CSV.exists() and TEST_CSV.exists(), \"Make sure Train.csv and Test.csv are present.\"\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(train_df.head(), '\\n', test_df.head())\n",
    "print('Train size:', len(train_df), ' Test size:', len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae299c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resolve_image_path(img_id, images_dir=IMAGES_DIR):\n",
    "    # Try common extensions. The CSV appears to include IDs without extension.\n",
    "    for ext in IMG_EXTS:\n",
    "        p = images_dir / f\"{img_id}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # Sometimes the ID already includes an extension:\n",
    "    p = images_dir / img_id\n",
    "    if p.exists():\n",
    "        return p\n",
    "    raise FileNotFoundError(f\"Could not find image for id={img_id} under {images_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaizeDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, mode='train', transform=None):\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            assert 'Label' in self.df.columns, \"Train/val dataframe must have a 'Label' column.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['Image_id']\n",
    "        img_path = resolve_image_path(img_id, self.images_dir)\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return img, img_id\n",
    "        else:\n",
    "            label = float(row['Label'])\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "            return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f89c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 224  # Fits K80 easily; can try 256/320 later\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_split, valid_split = train_test_split(\n",
    "    train_df, test_size=0.2, stratify=train_df['Label'], random_state=SEED\n",
    ")\n",
    "print('Split sizes:', len(train_split), len(valid_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32   # for K80; adjust to 64 if memory allows\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_ds = MaizeDataset(train_split, IMAGES_DIR, mode='train', transform=train_tfms)\n",
    "valid_ds = MaizeDataset(valid_split, IMAGES_DIR, mode='train', transform=valid_tfms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "len(train_loader), len(valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeaf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    # ResNet18 is a strong/light baseline\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    # Replace head\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feats, 1)\n",
    "    return model\n",
    "\n",
    "model = build_model().to(device)\n",
    "sum(p.numel() for p in model.parameters())/1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, mode='max', min_delta=1e-4):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.best = -np.inf if mode=='max' else np.inf\n",
    "        self.wait = 0\n",
    "\n",
    "    def step(self, value):\n",
    "        improved = (value > self.best + self.min_delta) if self.mode=='max' else (value < self.best - self.min_delta)\n",
    "        if improved:\n",
    "            self.best = value\n",
    "            self.wait = 0\n",
    "            return True  # signal to save\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            return False  # no save\n",
    "\n",
    "    def should_stop(self):\n",
    "        return self.wait >= self.patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for (imgs, labels) in tqdm(loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(imgs)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_probs, all_targets = [], []\n",
    "    for (imgs, labels) in tqdm(loader, leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True).unsqueeze(1)\n",
    "        logits = model(imgs)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        all_probs.append(probs.detach().cpu().numpy())\n",
    "        all_targets.append(labels.detach().cpu().numpy())\n",
    "    all_probs = np.vstack(all_probs).ravel()\n",
    "    all_targets = np.vstack(all_targets).ravel()\n",
    "    auc = roc_auc_score(all_targets, all_probs)\n",
    "    return auc, all_probs, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f0fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 10\n",
    "LR = 3e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "early = EarlyStopper(patience=3, mode='max')\n",
    "\n",
    "best_auc = -1\n",
    "best_path = 'best_resnet18.pt'\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    val_auc, _, _ = evaluate(model, valid_loader)\n",
    "    print(f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}  val_auc={val_auc:.4f}\")\n",
    "    if early.step(val_auc):\n",
    "        torch.save({'model': model.state_dict(), 'auc': val_auc}, best_path)\n",
    "        print(f\"  ✓ Saved new best model (AUC={val_auc:.4f})\")\n",
    "    if early.should_stop():\n",
    "        print(\"Early stopping.\")\n",
    "        break\n",
    "\n",
    "print('Best AUC recorded:', early.best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca206144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload best\n",
    "ckpt = torch.load('best_resnet18.pt', map_location=device)\n",
    "model.load_state_dict(ckpt['model'])\n",
    "model.eval()\n",
    "\n",
    "test_ds = MaizeDataset(test_df, IMAGES_DIR, mode='test', transform=valid_tfms)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "probs_list, ids = [], []\n",
    "@torch.no_grad()\n",
    "def predict_tta(imgs, model):\n",
    "    # simple 2x TTA: original + hflip\n",
    "    logits = model(imgs)\n",
    "    logits_flip = model(torch.flip(imgs, dims=[3]))  # horizontal flip\n",
    "    probs = torch.sigmoid((logits + logits_flip) / 2.0)\n",
    "    return probs\n",
    "\n",
    "for (imgs, img_ids) in tqdm(test_loader):\n",
    "    imgs = imgs.to(device, non_blocking=True)\n",
    "    probs = predict_tta(imgs, model)\n",
    "    probs_list.append(probs.detach().cpu().numpy().ravel())\n",
    "    ids.extend(img_ids)\n",
    "\n",
    "probs = np.concatenate(probs_list)\n",
    "sub = pd.DataFrame({'Image_id': ids, 'Label': probs})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print(sub.head())\n",
    "print('Wrote submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7941ee",
   "metadata": {},
   "source": [
    "\n",
    "## Tips & Next Steps\n",
    "- Try larger input (`IMG_SIZE=256`/`320`) if time allows.\n",
    "- Increase **epochs** to ~15–20 with early stopping.\n",
    "- Try **ResNet34** or **EfficientNet** (if allowed through `torchvision` or `timm`).\n",
    "- Use **StratifiedKFold** (3–5 folds) and **average predictions** (ensembling) within time limits.\n",
    "- Add **MixUp/CutMix**, or stronger augmentations.\n",
    "- Use **label smoothing** (e.g., BCE with smoothing) to regularize.\n",
    "- Add **Test-Time Augmentation (TTA)** with more flips/rotations (respecting inference time caps).\n",
    "- Always submit **probabilities** (not rounded values) to optimize AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Export to TorchScript (for mobile/edge)\n",
    "example = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "traced = torch.jit.trace(model, example)\n",
    "ts_path = \"resnet18_faw.torchscript.pt\"\n",
    "traced.save(ts_path)\n",
    "print(\"Saved TorchScript model to\", ts_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
